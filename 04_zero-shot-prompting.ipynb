{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero-Shot Prompting Tutorial\n",
    "\n",
    "## Overview\n",
    "\n",
    "This Notebook provides a comprehensive introduction to zero-shot prompting, a powerful technique in prompt engineering that allows language models to perform tasks without specific examples or prior training. We'll explore how to design effective zero-shot prompts and implement strategies using OpenAI's GPT models and the LangChain library.\n",
    "\n",
    "## Motivation\n",
    "\n",
    "Zero-shot prompting is crucial in modern AI applications as it enables language models to generalize to new tasks without the need for task-specific training data or fine-tuning. This capability significantly enhances the flexibility and applicability of AI systems, allowing them to adapt to a wide range of scenarios and user needs with minimal setup.\n",
    "\n",
    "## Key Components\n",
    "\n",
    "1. **Understanding Zero-Shot Learning**: An introduction to the concept and its importance in AI.\n",
    "2. **Prompt Design Principles**: Techniques for crafting effective zero-shot prompts.\n",
    "3. **Task Framing**: Methods to frame various tasks for zero-shot performance.\n",
    "4. **OpenAI Integration**: Using OpenAI's GPT models for zero-shot tasks.\n",
    "5. **LangChain Implementation**: Leveraging LangChain for structured zero-shot prompting.\n",
    "\n",
    "## Method Details\n",
    "\n",
    "The Notebook will cover several methods for implementing zero-shot prompting:\n",
    "\n",
    "1. **Direct Task Specification**: Crafting prompts that clearly define the task without examples.\n",
    "2. **Role-Based Prompting**: Assigning specific roles to the AI to guide its responses.\n",
    "3. **Format Specification**: Providing output format guidelines in the prompt.\n",
    "4. **Multi-step Reasoning**: Breaking down complex tasks into simpler zero-shot steps.\n",
    "5. **Comparative Analysis**: Evaluating different zero-shot prompt structures for the same task.\n",
    "\n",
    "Throughout the tutorial, we'll use Python code with OpenAI and LangChain to demonstrate these techniques practically.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "By the end of this Notebook, learners will have gained:\n",
    "\n",
    "1. A solid understanding of zero-shot prompting and its applications.\n",
    "2. Practical skills in designing effective zero-shot prompts for various tasks.\n",
    "3. Experience in implementing zero-shot techniques using OpenAI and LangChain.\n",
    "4. Insights into the strengths and limitations of zero-shot approaches.\n",
    "5. A foundation for further exploration and innovation in prompt engineering.\n",
    "\n",
    "This knowledge will empower learners to leverage AI models more effectively across a wide range of applications, enhancing their ability to solve novel problems and create more flexible AI systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Let's start by importing the necessary libraries and setting up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# # Load environment variables\n",
    "# load_dotenv()\n",
    "\n",
    "# # Set up OpenAI API key\n",
    "# os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Initialize the language model\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "\n",
    "def create_chain(prompt_template):\n",
    "    \"\"\"\n",
    "    Create a LangChain chain with the given prompt template.\n",
    "    \n",
    "    Args:\n",
    "        prompt_template (str): The prompt template string.\n",
    "    \n",
    "    Returns:\n",
    "        LLMChain: A LangChain chain object.\n",
    "    \"\"\"\n",
    "    prompt = PromptTemplate.from_template(prompt_template)\n",
    "    return prompt | llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Direct Task Specification\n",
    "\n",
    "In this section, we'll explore how to craft prompts that clearly define the task without providing examples. This is the essence of zero-shot prompting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "direct_task_prompt = \"\"\"Classify the sentiment of the following text as positive, negative, or neutral.\n",
    "Do not explain your reasoning, just provide the classification.\n",
    "\n",
    "Text: {text}\n",
    "\n",
    "Sentiment:\"\"\"\n",
    "\n",
    "direct_task_chain = create_chain(direct_task_prompt)\n",
    "\n",
    "# Test the direct task specification\n",
    "texts = [\n",
    "    \"I absolutely loved the movie! The acting was superb.\",\n",
    "    \"The weather today is quite typical for this time of year.\",\n",
    "    \"I'm disappointed with the service I received at the restaurant.\"\n",
    "]\n",
    "\n",
    "for text in texts:\n",
    "    result = direct_task_chain.invoke({\"text\": text}).content\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Sentiment: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Format Specification\n",
    "\n",
    "Providing output format guidelines in the prompt can help structure the AI's response in a zero-shot scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_spec_prompt = \"\"\"Generate a short news article about {topic}. \n",
    "Structure your response in the following format:\n",
    "\n",
    "Headline: [A catchy headline for the article]\n",
    "\n",
    "Lead: [A brief introductory paragraph summarizing the key points]\n",
    "\n",
    "Body: [2-3 short paragraphs providing more details]\n",
    "\n",
    "Conclusion: [A concluding sentence or call to action]\"\"\"\n",
    "\n",
    "format_spec_chain = create_chain(format_spec_prompt)\n",
    "\n",
    "# Test the format specification prompting\n",
    "topic = \"The discovery of a new earth-like exoplanet\"\n",
    "result = format_spec_chain.invoke({\"topic\": topic}).content\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Multi-step Reasoning\n",
    "\n",
    "For complex tasks, we can break them down into simpler zero-shot steps. This approach can improve the overall performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_step_prompt = \"\"\"Analyze the following text for its main argument, supporting evidence, and potential counterarguments. \n",
    "Provide your analysis in the following steps:\n",
    "\n",
    "1. Main Argument: Identify and state the primary claim or thesis.\n",
    "2. Supporting Evidence: List the key points or evidence used to support the main argument.\n",
    "3. Potential Counterarguments: Suggest possible objections or alternative viewpoints to the main argument.\n",
    "\n",
    "Text: {text}\n",
    "\n",
    "Analysis:\"\"\"\n",
    "\n",
    "multi_step_chain = create_chain(multi_step_prompt)\n",
    "\n",
    "# Test the multi-step reasoning approach\n",
    "text = \"\"\"While electric vehicles are often touted as a solution to climate change, their environmental impact is not as straightforward as it seems. \n",
    "The production of batteries for electric cars requires significant mining operations, which can lead to habitat destruction and water pollution. \n",
    "Moreover, if the electricity used to charge these vehicles comes from fossil fuel sources, the overall carbon footprint may not be significantly reduced. \n",
    "However, as renewable energy sources become more prevalent and battery technology improves, electric vehicles could indeed play a crucial role in combating climate change.\"\"\"\n",
    "\n",
    "result = multi_step_chain.invoke({\"text\": text}).content\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Comparative Analysis\n",
    "\n",
    "Let's compare different zero-shot prompt structures for the same task to evaluate their effectiveness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_prompts(task, prompt_templates):\n",
    "    \"\"\"\n",
    "    Compare different prompt templates for the same task.\n",
    "    \n",
    "    Args:\n",
    "        task (str): The task description or input.\n",
    "        prompt_templates (dict): A dictionary of prompt templates with their names as keys.\n",
    "    \"\"\"\n",
    "    print(f\"Task: {task}\\n\")\n",
    "    for name, template in prompt_templates.items():\n",
    "        chain = create_chain(template)\n",
    "        result = chain.invoke({\"task\": task}).content\n",
    "        print(f\"{name} Prompt Result:\")\n",
    "        print(result)\n",
    "        print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "\n",
    "task = \"Explain conciesly the concept of blockchain technology\"\n",
    "\n",
    "prompt_templates = {\n",
    "    \"Basic\": \"Explain {task}.\",\n",
    "    \"Structured\": \"\"\"Explain {task} by addressing the following points:\n",
    "1. Definition\n",
    "2. Key features\n",
    "3. Real-world applications\n",
    "4. Potential impact on industries\"\"\"\n",
    "}\n",
    "\n",
    "compare_prompts(task, prompt_templates)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
